{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "123S1C_eWmD5NY-z4SROTux-0RB7Eb1UV",
      "authorship_tag": "ABX9TyNriJcdnyqzr2yvBW9zScp0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tihunn/emotion_testing/blob/main/exp/all_files_from_dasha_expirements.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "metrics.py"
      ],
      "metadata": {
        "id": "Igb0lET8giMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "\n",
        "def get_metrics_df(pred_class, gt_class, model_name=None):\n",
        "    metric_dict = calculate_metrics(pred_class=pred_class, gt_class=gt_class)\n",
        "    metrics_df = pd.DataFrame([metric_dict]).T.round(4)\n",
        "\n",
        "    if model_name is not None:\n",
        "        metrics_df.columns = [model_name]\n",
        "\n",
        "    return metrics_df\n",
        "\n",
        "\n",
        "def weighted_accuracy(y_true, y_pred, n_classes=4):\n",
        "    y_pred = np.array(y_pred)\n",
        "    y_true = np.array(y_true)\n",
        "\n",
        "    class_accuracies = []\n",
        "    for i in range(n_classes):\n",
        "        gt_class_mask = y_true == i\n",
        "        pred_class_mask = y_pred == i\n",
        "        class_accuracies.append(\n",
        "            (gt_class_mask * pred_class_mask).sum() / gt_class_mask.sum()\n",
        "        )\n",
        "\n",
        "    return np.mean(class_accuracies)\n",
        "\n",
        "\n",
        "def calculate_metrics(pred_class, gt_class, **kwargs):\n",
        "    n_classes = 4\n",
        "\n",
        "    metrics_dict = {\n",
        "        \"accuracy\": accuracy_score(y_true=gt_class, y_pred=pred_class),\n",
        "        \"WA\": weighted_accuracy(\n",
        "            y_true=gt_class, y_pred=pred_class, n_classes=n_classes\n",
        "        ),\n",
        "        \"f1_macro\": f1_score(y_true=gt_class, y_pred=pred_class, average=\"macro\"),\n",
        "    }\n",
        "\n",
        "    return metrics_dict"
      ],
      "metadata": {
        "id": "dWGBELqNgj6N"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "learner.py"
      ],
      "metadata": {
        "id": "5DNGdtnogDia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam, lr_scheduler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class Learner:\n",
        "    def __init__(\n",
        "        self,\n",
        "        train_dataset,\n",
        "        val_dataset,\n",
        "        dataloaders,\n",
        "        exp_path,\n",
        "        model_name,\n",
        "        model,\n",
        "        batch_size,\n",
        "        dump_best_checkpoints,\n",
        "        dump_last_checkpoints,\n",
        "        best_checkpoints_warmup,\n",
        "        cuda_device=\"cuda:0\",\n",
        "    ):\n",
        "\n",
        "        self.device = torch.device(cuda_device if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        self.__model_name = model_name\n",
        "\n",
        "        self.dump_last_checkpoints = dump_last_checkpoints\n",
        "        self.dump_best_checkpoints = dump_best_checkpoints\n",
        "        self.best_checkpoints_warmup = best_checkpoints_warmup\n",
        "\n",
        "        self.exp_path = Path(exp_path)\n",
        "        if dump_best_checkpoints:\n",
        "            self.best_checkpoints_path = self.exp_path / \"best_checkpoints\"\n",
        "            self.best_checkpoints_path.mkdir()\n",
        "        if dump_last_checkpoints:\n",
        "            self.last_checkpoints_path = self.exp_path / (\n",
        "                self.__model_name + \"_last_checkpoints\"\n",
        "            )\n",
        "            self.last_checkpoints_path.mkdir()\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.train_dataset = train_dataset\n",
        "        self.val_dataset = val_dataset\n",
        "\n",
        "        print(\n",
        "            \"train labels\",\n",
        "            np.unique(self.train_dataset.df.label.values, return_counts=True),\n",
        "        )\n",
        "        print(\n",
        "            \"train weights\",\n",
        "            np.unique(\n",
        "                self.train_dataset.df.sampling_weights.values, return_counts=True\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        self.dataloaders = dataloaders\n",
        "\n",
        "        self.dataset_sizes = {\n",
        "            \"train\": len(self.train_dataset.df),\n",
        "            \"validate\": len(self.val_dataset.df),\n",
        "        }\n",
        "\n",
        "    def train(self, num_epochs, lr, step_size, gamma, weight_decay=0, clip_grad=False):\n",
        "        comment_str_list = [\n",
        "            \"MODEL\",\n",
        "            self.__model_name,\n",
        "            \"EPOCHS\",\n",
        "            str(num_epochs),\n",
        "            \"LR\",\n",
        "            str(lr),\n",
        "            \"BATCH\",\n",
        "            str(self.batch_size),\n",
        "        ]\n",
        "\n",
        "        comment_str = \"_\".join(comment_str_list)\n",
        "        summary_writer = SummaryWriter(log_dir=self.exp_path / 'TB_log' / comment_str)\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "        since = time.time()\n",
        "        # copy.deepcopy(self.model.state_dict())\n",
        "        best_model_wts = None\n",
        "        best_loss = 10000000\n",
        "        best_acc = best_f1 = best_WA = 0\n",
        "        softmax = nn.Softmax(dim=1)\n",
        "\n",
        "        try:\n",
        "            for epoch in range(1, num_epochs + 1):\n",
        "                print(f\"Epoch {epoch}/{num_epochs}\")\n",
        "                for phase in [\"train\", \"validate\"]:\n",
        "                    if phase == \"train\":\n",
        "                        self.model.train()\n",
        "                        cur_step_lr = scheduler.get_last_lr()[-1]\n",
        "                    else:\n",
        "                        self.model.eval()\n",
        "\n",
        "                    running_loss = 0.0\n",
        "                    running_outputs = []\n",
        "                    running_labels = []\n",
        "                    for inputs, labels in tqdm(self.dataloaders[phase]):\n",
        "                        inputs = inputs.to(self.device)\n",
        "                        labels = labels.long()\n",
        "                        labels = labels.to(self.device)\n",
        "                        optimizer.zero_grad()\n",
        "\n",
        "                        with torch.set_grad_enabled(phase == \"train\"):\n",
        "                            outputs = self.model(inputs)\n",
        "                            probs = softmax(outputs)\n",
        "                            loss = criterion(outputs, labels)\n",
        "                            if phase == \"train\":\n",
        "                                loss.backward()\n",
        "                                if clip_grad:\n",
        "                                    torch.nn.utils.clip_grad_norm_(\n",
        "                                        self.model.parameters(), 1.0\n",
        "                                    )\n",
        "                                optimizer.step()\n",
        "\n",
        "                        running_loss += loss.item()\n",
        "                        if phase == \"validate\":\n",
        "                            running_labels.append(labels)\n",
        "                            running_outputs.append(probs)\n",
        "\n",
        "                    if phase == \"train\":\n",
        "                        scheduler.step()\n",
        "\n",
        "                    epoch_loss = running_loss / self.dataset_sizes[phase]\n",
        "                    if phase == \"validate\":\n",
        "                        pred_class = np.argmax(\n",
        "                            torch.cat(running_outputs).cpu().numpy(), axis=1\n",
        "                        )\n",
        "                        gt_class = torch.cat(running_labels).cpu().numpy()\n",
        "\n",
        "                        metric_dict = calculate_metrics(\n",
        "                            pred_class, gt_class, neg_label=0\n",
        "                        )\n",
        "\n",
        "                        summary_writer.add_scalar(\"Loss/validate\", epoch_loss, epoch)\n",
        "                        for metric_name, metric_value in metric_dict.items():\n",
        "                            summary_writer.add_scalar(\n",
        "                                f\"Metrics/{metric_name}\", metric_value, epoch\n",
        "                            )\n",
        "\n",
        "                        epoch_acc = metric_dict[\"accuracy\"]\n",
        "                        epoch_f1 = metric_dict[\"f1_macro\"]\n",
        "                        epoch_WA = metric_dict[\"WA\"]\n",
        "\n",
        "                        print(f\"{phase} Loss: {epoch_loss:.4f}\")\n",
        "                        print(f\"{phase} Acc: {epoch_acc:.4f}\")\n",
        "                        print(f\"{phase} F1 macro: {epoch_f1:.4f}\")\n",
        "                        print(f\"{phase} WA: {epoch_WA:.4f}\")\n",
        "\n",
        "                        if epoch_f1 > best_f1:\n",
        "                            best_f1 = epoch_f1\n",
        "                            # best_WA = epoch_WA\n",
        "                            best_acc = epoch_acc\n",
        "                            best_f1 = epoch_f1\n",
        "\n",
        "                            best_epoch = epoch\n",
        "                            best_model_wts = copy.deepcopy(self.model.state_dict())\n",
        "\n",
        "                            if (\n",
        "                                self.dump_best_checkpoints\n",
        "                                and epoch > self.best_checkpoints_warmup\n",
        "                            ):\n",
        "                                torch.save(\n",
        "                                    best_model_wts,\n",
        "                                    self.best_checkpoints_path\n",
        "                                    / f\"best_checkpoint_{epoch}\",\n",
        "                                )\n",
        "\n",
        "                        if self.dump_last_checkpoints and abs(epoch - num_epochs) < 6:\n",
        "                            torch.save(\n",
        "                                copy.deepcopy(self.model.state_dict()),\n",
        "                                self.last_checkpoints_path / f\"checkpoint_{epoch}\",\n",
        "                            )\n",
        "\n",
        "                    else:\n",
        "                        print(f\"{phase} Loss: {epoch_loss:.4f}\")\n",
        "                        summary_writer.add_scalar(\"Loss/train\", epoch_loss, epoch)\n",
        "                        summary_writer.add_scalar(\"LR/value\", cur_step_lr, epoch)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            pass\n",
        "\n",
        "        summary_writer.flush()\n",
        "        time_elapsed = time.time() - since\n",
        "        print(\n",
        "            f\"Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s.\"\n",
        "            + f\" Best model loss: {best_loss:.6f}, best model acc: {best_acc:.6f}, \"\n",
        "            + f\"best model f1: {best_f1:.6f}, best epoch {best_epoch}\"\n",
        "        )\n",
        "\n",
        "        self.model.load_state_dict(best_model_wts)\n",
        "        self.model.eval()\n",
        "        return best_model_wts"
      ],
      "metadata": {
        "id": "Tw1jx8n4gFof"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "datasets.py"
      ],
      "metadata": {
        "id": "yxrhdq2of49F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BLZ11AqYf3ww"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.distributions.categorical import Categorical\n",
        "from torch.utils.data import Dataset, Sampler\n",
        "from torchaudio import transforms as T\n",
        "from torchvision import transforms\n",
        "\n",
        "PATH_TO_TENSOR_COL = \"tensor\"\n",
        "\n",
        "\n",
        "def load_tensor(path):\n",
        "    features_tensor = np.fromfile(path, dtype=np.float32)\n",
        "    return torch.from_numpy(np.reshape(features_tensor, (-1, 64)))\n",
        "\n",
        "\n",
        "def pad_or_crop_to_shape(tensor, size, rand_side_pad=True):\n",
        "    assert len(tensor.shape) == 3\n",
        "    delta = size - tensor.shape[-1]\n",
        "    if delta > 0:\n",
        "        if rand_side_pad:\n",
        "            start_padding = np.random.randint(delta)\n",
        "            end_padding = delta - start_padding\n",
        "            res = nn.functional.pad(tensor, pad=(start_padding, end_padding, 0, 0))\n",
        "        else:\n",
        "            res = nn.functional.pad(tensor, pad=(0, delta, 0, 0))\n",
        "\n",
        "        return res\n",
        "    else:\n",
        "        return tensor[..., :size]\n",
        "\n",
        "\n",
        "def adaptive_padding_collate_fn(batch):\n",
        "    data = []\n",
        "    target = []\n",
        "    max_size = max([tens.shape[-1] for (tens, label) in batch])\n",
        "    for (tens, label) in batch:\n",
        "        # crop\n",
        "        data.append(pad_or_crop_to_shape(tens, max_size, rand_side_pad=True))\n",
        "        target.append(label)\n",
        "\n",
        "    return torch.stack(data), torch.tensor(target)\n",
        "\n",
        "\n",
        "def get_augm_func(time_mask_param=80, freq_mask_param=16, crop_augm_max_cut_size=0):\n",
        "    \"\"\"\n",
        "    Returns function for augmentation in MelEmotionsDataset (augm_transform)\n",
        "    Returned function's input should have [bs, 1, T] shape\n",
        "\n",
        "    :param time_mask_param:\n",
        "    :param freq_mask_param:\n",
        "    :param crop_augm_max_cut_size: if 0 - random crops are not used\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    t_masking = T.TimeMasking(time_mask_param=time_mask_param)\n",
        "    f_masking = T.FrequencyMasking(freq_mask_param=freq_mask_param)\n",
        "\n",
        "    if crop_augm_max_cut_size != 0:\n",
        "        # we want random crop with random size,\n",
        "        # so we should sample crop size for each augm_transform call\n",
        "        def crop_f(tens):\n",
        "            crop_delta = np.random.randint(crop_augm_max_cut_size)\n",
        "            random_crop = transforms.RandomCrop(\n",
        "                np.array(tens.shape)[1:] - np.array([0, crop_delta])\n",
        "            )\n",
        "\n",
        "            return random_crop(tens)\n",
        "\n",
        "        augm_transform = transforms.Compose([f_masking, t_masking, crop_f])\n",
        "    else:\n",
        "        augm_transform = transforms.Compose([f_masking, t_masking])\n",
        "\n",
        "    return augm_transform\n",
        "\n",
        "\n",
        "class MelEmotionsDataset(Dataset):\n",
        "    def __init__(\n",
        "        self, df, *_, augm_transform=None, get_weights_func=None, base_path=None, **__\n",
        "    ):\n",
        "        super().__init__()\n",
        "        df = df.copy()\n",
        "        if \"label\" in df.columns:\n",
        "            df[\"label\"] = df[\"label\"].apply(int)\n",
        "        else:\n",
        "            print('There is no column \"label\" in the TSV')\n",
        "\n",
        "        if get_weights_func is None:\n",
        "            df[\"sampling_weights\"] = 1\n",
        "        else:\n",
        "            df[\"sampling_weights\"] = get_weights_func(df)\n",
        "\n",
        "        # sort by length\n",
        "        if \"wav_length\" in df.columns:\n",
        "            df = df.sort_values(\"wav_length\").reset_index(drop=True)\n",
        "        else:\n",
        "            print('There is no column \"wav_length\" in the TSV')\n",
        "\n",
        "        self.df = df\n",
        "        self.augm_transform = augm_transform\n",
        "        self.feature_col = PATH_TO_TENSOR_COL\n",
        "\n",
        "        if base_path is not None:\n",
        "            base_path = Path(base_path)\n",
        "        self.base_path = base_path\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        path = self.df.iloc[idx][self.feature_col]\n",
        "        if self.base_path is not None:\n",
        "            path = self.base_path / path\n",
        "\n",
        "        tens = torch.from_numpy(np.load(path))\n",
        "        label = self.df.iloc[idx][\"label\"]\n",
        "\n",
        "        if self.augm_transform is not None:\n",
        "            tens = self.augm_transform(tens)\n",
        "\n",
        "        return tens, label\n",
        "\n",
        "\n",
        "class LengthWeightedSampler(Sampler[int]):\n",
        "    def __init__(\n",
        "        self,\n",
        "        df,\n",
        "        batch_size,\n",
        "        min_length=1,\n",
        "        max_length=20.5,\n",
        "        length_delta=0.3,\n",
        "        decimals=1,\n",
        "    ):\n",
        "        # df should be sorted ascending by wav_length\n",
        "        # we do it in MelEmotionsDataset\n",
        "        if \"wav_length\" not in df.columns:\n",
        "            raise ValueError('There is no column \"wav_length\" in the TSV')\n",
        "\n",
        "        super().__init__(df)\n",
        "        self.df = df\n",
        "        self.batch_size = batch_size\n",
        "        self.num_samples = (len(df) // batch_size) * batch_size\n",
        "\n",
        "        all_lengths = np.round(df[\"wav_length\"].values, decimals)\n",
        "        _max = max(all_lengths)\n",
        "        _min = min(all_lengths)\n",
        "\n",
        "        if max_length is None or max_length > _max:\n",
        "            max_length = _max\n",
        "        if min_length is None or min_length < _min:\n",
        "            min_length = _min\n",
        "\n",
        "        self.min_length = min_length\n",
        "        self.max_length = max_length\n",
        "        self.length_delta = length_delta\n",
        "\n",
        "        self.decimals = decimals\n",
        "        self.length_step = np.round(0.1 ** decimals, decimals)\n",
        "\n",
        "        # is needed to sample batches with max length inclusive\n",
        "        max_plus_delta = np.round(self.max_length + self.length_step, decimals)\n",
        "\n",
        "        length_to_index_mapping = {}\n",
        "        temp_length = 0\n",
        "\n",
        "        for i, v in enumerate(all_lengths):\n",
        "            if v > temp_length:\n",
        "                if v != temp_length + self.length_step:\n",
        "                    for j in np.arange(\n",
        "                        temp_length + self.length_step, v, self.length_step\n",
        "                    ):\n",
        "                        length_to_index_mapping[np.round(j, decimals)] = i\n",
        "\n",
        "                length_to_index_mapping[v] = i\n",
        "\n",
        "                temp_length = v\n",
        "\n",
        "        # fix to sample batches with max length inclusive\n",
        "        length_to_index_mapping[\n",
        "            np.round(np.max(all_lengths) + self.length_step, decimals)\n",
        "        ] = len(df)\n",
        "\n",
        "        self.length_to_index_mapping = length_to_index_mapping\n",
        "\n",
        "        # starts with MIN_LENGTH\n",
        "        self.lengths, self.lengths_count = np.unique(\n",
        "            all_lengths[\n",
        "                length_to_index_mapping[self.min_length] : length_to_index_mapping[\n",
        "                    max_plus_delta\n",
        "                ]\n",
        "            ],\n",
        "            return_counts=True,\n",
        "        )\n",
        "\n",
        "        self.key_length_sampler = Categorical(\n",
        "            probs=torch.from_numpy(self.lengths_count)\n",
        "        )\n",
        "\n",
        "    def __iter__(self):\n",
        "        N = 0\n",
        "        res_indexes = []\n",
        "\n",
        "        while N < self.num_samples:\n",
        "            key_length = self.lengths[self.key_length_sampler.sample().item()]\n",
        "\n",
        "            batch_min_length = np.round(\n",
        "                max(self.min_length, key_length - self.length_delta), self.decimals\n",
        "            )\n",
        "            batch_max_length = np.round(\n",
        "                min(self.max_length, key_length + self.length_delta), self.decimals\n",
        "            )\n",
        "            batch_max_length_plus_delta = np.round(\n",
        "                batch_max_length + self.length_step, self.decimals\n",
        "            )\n",
        "\n",
        "            sub_df = self.df.iloc[\n",
        "                self.length_to_index_mapping[\n",
        "                    batch_min_length\n",
        "                ] : self.length_to_index_mapping[batch_max_length_plus_delta]\n",
        "            ][[\"sampling_weights\"]]\n",
        "\n",
        "            sampling_weights = torch.from_numpy(\n",
        "                sub_df.sampling_weights.values.astype(float)\n",
        "            )\n",
        "            sub_iloc_indexes = torch.multinomial(\n",
        "                sampling_weights, self.batch_size, True\n",
        "            ).tolist()\n",
        "\n",
        "            batch_indexes = sub_df.iloc[sub_iloc_indexes].index.tolist()\n",
        "            res_indexes.extend(batch_indexes)\n",
        "\n",
        "            N += self.batch_size\n",
        "\n",
        "        return iter(res_indexes)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "untils.py"
      ],
      "metadata": {
        "id": "0CBUPOzggNg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def parse_name(tsv_name):\n",
        "    \"\"\"\n",
        "    We have names like\n",
        "    f\"predicts_dataset_{dataset_name}_model_{model_name}.tsv\" /\n",
        "    f\"metrics_dataset_{dataset_name}_model_{model_name}.csv\"\n",
        "\n",
        "    Returns: dataset_name, model_name\n",
        "    \"\"\"\n",
        "\n",
        "    if tsv_name.startswith(\"predicts_dataset_\"):\n",
        "        # len('predicts_dataset_') = 17\n",
        "        _s = tsv_name[17:]\n",
        "    elif tsv_name.startswith(\"metrics_dataset_\"):\n",
        "        _s = tsv_name[16:]\n",
        "    else:\n",
        "        raise ValueError(f\"tsv_name is {tsv_name}\")\n",
        "\n",
        "    model_prefix_start = _s.find(\"_model_\")\n",
        "    if model_prefix_start == -1:\n",
        "        raise ValueError(f\"tsv_name is {tsv_name}\")\n",
        "\n",
        "    dataset_name = _s[:model_prefix_start]\n",
        "    model_name = _s[model_prefix_start + len(\"_model_\") : -4]\n",
        "\n",
        "    return dataset_name, model_name\n",
        "\n",
        "\n",
        "def raw_parse_dir(exps_path, prefix=\"predicts\"):\n",
        "    \"\"\"\n",
        "    Pars dir with experiments and returns dicts:\n",
        "        dataset: model: path\n",
        "        dataset: set of models\n",
        "\n",
        "    Args:\n",
        "        exps_path: path to dir with experiments\n",
        "        prefix: 'predicts' or 'metrics' - what the function should parse\n",
        "    \"\"\"\n",
        "    exps_path = Path(exps_path)\n",
        "\n",
        "    # get paths to data\n",
        "    glob_exp = \"**/\"\n",
        "\n",
        "    if prefix == \"predicts\":\n",
        "        glob_file = \"predicts_*.tsv\"\n",
        "    elif prefix == \"metrics\":\n",
        "        glob_file = \"metrics_*.csv\"\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            f\"Get prefix = {prefix}, supports only ['predicts', 'metrics']\"\n",
        "        )\n",
        "\n",
        "    data_paths = list(exps_path.glob(glob_exp + glob_file))\n",
        "\n",
        "    data_paths = [\n",
        "        p\n",
        "        for p in data_paths\n",
        "        if str(p.name).startswith(prefix)\n",
        "        and str(p.name).find(\"dataset_\") > -1\n",
        "        and str(p.name).find(\"model_\") > -1\n",
        "    ]\n",
        "\n",
        "    # init our structure\n",
        "    # dataset: model: path_to_predict\n",
        "    dataset_models_paths = {}\n",
        "\n",
        "    # get all models for all datasets\n",
        "\n",
        "    # dataset: set of model names\n",
        "    dataset_models_dict = {}\n",
        "    for curr_path in data_paths:\n",
        "        dataset_name, model_name = parse_name(str(curr_path.name))\n",
        "        if dataset_models_dict.get(dataset_name) is None:\n",
        "            dataset_models_dict[dataset_name] = {model_name}\n",
        "            dataset_models_paths[dataset_name] = {model_name: curr_path}\n",
        "        else:\n",
        "            dataset_models_dict[dataset_name] |= {model_name}\n",
        "            dataset_models_paths[dataset_name].update({model_name: curr_path})\n",
        "\n",
        "    return dataset_models_paths, dataset_models_dict\n",
        "\n",
        "\n",
        "def collect_metrics_to_one(list_of_metrics_df):\n",
        "    df = list_of_metrics_df[0]\n",
        "    df.columns = [\"\", df.columns[-1]]\n",
        "    df = df.set_index(\"\")\n",
        "\n",
        "    for curr_metric_df in list_of_metrics_df[1:]:\n",
        "        _df = curr_metric_df\n",
        "        _df.columns = [\"\", _df.columns[-1]]\n",
        "        _df = _df.set_index(\"\")\n",
        "        df = df.join(_df)\n",
        "\n",
        "    df = df.sort_values(\"f1_macro\", axis=1, ascending=False)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def load_jsonl_as_df(file_name):\n",
        "    data = []\n",
        "    with open(file_name, \"r\") as file1:\n",
        "        for line1 in file1:\n",
        "            data.append(json.loads(line1))\n",
        "    file1.close()\n",
        "    df = pd.DataFrame.from_records(data)\n",
        "    if \"label\" in df.columns:\n",
        "        df.label = df.label.astype(int)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "uDUcdQEwgNNU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.py"
      ],
      "metadata": {
        "id": "3kTk-kdOgbkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Union\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.mobilenetv2 import InvertedResidual, _make_divisible\n",
        "\n",
        "\n",
        "class ConvBNReLU(nn.Sequential):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size=3, stride=1, groups=1, norm_layer=None):\n",
        "        padding = (kernel_size - 1) // 2\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        super(ConvBNReLU, self).__init__(\n",
        "            nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, groups=groups, bias=False),\n",
        "            norm_layer(out_planes),\n",
        "            nn.ReLU6(inplace=True)\n",
        "        )\n",
        "\n",
        "\n",
        "AUDIO_PROBAS = ('audio_neg', 'audio_sad', 'audio_neu', 'audio_pos')\n",
        "AUDIO_COLS = tuple([\"audio_pred\"] + list(AUDIO_PROBAS))\n",
        "\n",
        "EMO2LABEL = {'angry': 0,\n",
        "             'sad': 1,\n",
        "             'neutral': 2,\n",
        "             'positive': 3}\n",
        "\n",
        "\n",
        "class SoftMaxModel(nn.Module):\n",
        "    def __init__(self, logits_model: nn.Module):\n",
        "        super().__init__()\n",
        "        self.logits_model = logits_model\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.logits_model(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# slightly modified fast.ai implementation\n",
        "# https://medium.com/mlearning-ai/self-attention-in-convolutional-neural-networks-172d947afc00\n",
        "class ConvSelfAttention(nn.Module):\n",
        "    \"\"\"Self attention layer for `n_channels`.\"\"\"\n",
        "\n",
        "    def __init__(self, n_channels):\n",
        "        super().__init__()\n",
        "        self.query, self.key, self.value = [\n",
        "            self._conv(n_channels, c)\n",
        "            for c in (n_channels // 8, n_channels // 8, n_channels)\n",
        "        ]\n",
        "        self.gamma = nn.Parameter(torch.tensor([0.0]))\n",
        "\n",
        "    def _conv(self, n_in, n_out):\n",
        "        return nn.Conv1d(n_in, n_out, kernel_size=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Notation from the paper.\n",
        "        size = x.size()\n",
        "        x = x.view(*size[:2], -1)\n",
        "        f, g, h = self.query(x), self.key(x), self.value(x)\n",
        "        beta = nn.functional.softmax(torch.bmm(f.transpose(1, 2), g), dim=1)\n",
        "        o = self.gamma * torch.bmm(h, beta) + x\n",
        "        return o.view(*size).contiguous()\n",
        "\n",
        "\n",
        "# see deep_pipe\n",
        "# https://github.com/neuro-ml/deep_pipe/blob/master/dpipe/layers/shape.py#L48\n",
        "class Reshape(nn.Module):\n",
        "    \"\"\"\n",
        "    Reshape the incoming tensor to the given ``shape``.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    shape: Union[int, str]\n",
        "        the resulting shape. String values denote indices in the input tensor's shape.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> layer = Reshape('0', '1', 500, 500)\n",
        "    >>> layer(x)\n",
        "    >>> # same as\n",
        "    >>> x.reshape(x.shape[0], x.shape[1], 500, 500)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, *shape: Union[int, str]):\n",
        "        super().__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        shape = [x.shape[int(i)] if isinstance(i, str) else i for i in self.shape]\n",
        "        return x.reshape(*shape)\n",
        "\n",
        "\n",
        "# see torchvision.models.mobilenetv2.MobileNetV2\n",
        "class ConvSelfAttentionMobileNet(nn.Module):\n",
        "    def __init__(self, _config, n_classes, last_channel=128, in_channels=1):\n",
        "\n",
        "        super().__init__()\n",
        "        self._config = _config\n",
        "        self.in_channels = in_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.last_channel = last_channel\n",
        "\n",
        "        block = InvertedResidual\n",
        "        norm_layer = nn.BatchNorm2d\n",
        "        width_mult = 1.0\n",
        "        round_nearest = 8\n",
        "\n",
        "        input_channel = 4\n",
        "\n",
        "        features = [\n",
        "            ConvBNReLU(self.in_channels, input_channel, stride=1, norm_layer=norm_layer)\n",
        "        ]\n",
        "        for t, c, n, s in _config:\n",
        "            output_channel = _make_divisible(c * width_mult, round_nearest)\n",
        "            for i in range(n):\n",
        "                stride = s if i == 0 else 1\n",
        "                features.append(\n",
        "                    block(\n",
        "                        input_channel,\n",
        "                        output_channel,\n",
        "                        stride,\n",
        "                        expand_ratio=t,\n",
        "                        norm_layer=norm_layer,\n",
        "                    )\n",
        "                )\n",
        "                input_channel = output_channel\n",
        "        # building last several layers\n",
        "        features.append(\n",
        "            ConvBNReLU(\n",
        "                input_channel, self.last_channel, kernel_size=1, norm_layer=norm_layer\n",
        "            )\n",
        "        )\n",
        "        # make it nn.Sequential\n",
        "        self.features = nn.Sequential(*features)\n",
        "\n",
        "        self.pooling = nn.Sequential(\n",
        "            ConvSelfAttention(self.last_channel),\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            Reshape(\"0\", self.last_channel),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Linear(self.last_channel, self.n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.pooling(x)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "dU2bP2PIgbPB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train.py"
      ],
      "metadata": {
        "id": "rfr7LL79g1Hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lazycon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIAxfuQROwOZ",
        "outputId": "0f5ed937-ab45-44b2-dccf-1ce918178d02"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lazycon\n",
            "  Downloading lazycon-0.6.4.tar.gz (21 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: lazycon\n",
            "  Building wheel for lazycon (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lazycon: filename=lazycon-0.6.4-py3-none-any.whl size=20736 sha256=103b5e1bdd939f1a854dfce0812366e6d2aca9bcfd1c6e64d05655ee52a47782\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/40/f1/23fcbc40b224abb6381d572287f72b0e13e3cb2094cc43b3c2\n",
            "Successfully built lazycon\n",
            "Installing collected packages: lazycon\n",
            "Successfully installed lazycon-0.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "import click\n",
        "import lazycon\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "# @click.command()\n",
        "# @click.option(\n",
        "#     \"-config\",\n",
        "#     \"--config_path\",\n",
        "#     required=True,\n",
        "#     type=click.Path(exists=True),\n",
        "#     help=\"path to .config file\",\n",
        "# )\n",
        "# @click.option(\n",
        "#     \"-exp_path\",\n",
        "#     \"--exp_path\",\n",
        "#     required=True,\n",
        "#     type=click.Path(),\n",
        "#     help=\"path to dump experiment\",\n",
        "# )\n",
        "def train_model(config_path, exp_path):\n",
        "    exp_path = Path(exp_path)\n",
        "    model_name = exp_path.name\n",
        "    cfg = lazycon.load(config_path)\n",
        "    base_path = cfg.base_path\n",
        "    assert (\n",
        "        base_path.exists()\n",
        "    ), f\"{base_path} doesn't exist. Correct base_path in configs/data.config\"\n",
        "\n",
        "    exp_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # dump params\n",
        "    # save compiled config\n",
        "    cfg.dump(exp_path / \"train.config\")\n",
        "\n",
        "    # dump jsonls\n",
        "    shutil.copy(cfg.train_manifest_path, exp_path / \"train.jsonl\")\n",
        "    shutil.copy(cfg.val_manifest_path, exp_path / \"val.jsonl\")\n",
        "\n",
        "    model = cfg.model\n",
        "\n",
        "    # load pretrained model\n",
        "    if cfg.pt_model_path is not None:\n",
        "        model.load_state_dict(torch.load(cfg.pt_model_path, map_location=\"cuda:0\"))\n",
        "        shutil.copy(cfg.pt_model_path, exp_path / \"pt_model\")\n",
        "\n",
        "    # init learner\n",
        "    learner = Learner(\n",
        "        train_dataset=cfg.train_dataset,\n",
        "        val_dataset=cfg.val_dataset,\n",
        "        dataloaders=cfg.dataloaders,\n",
        "        exp_path=exp_path,\n",
        "        model_name=model_name,\n",
        "        model=model,\n",
        "        batch_size=cfg.batch_size,\n",
        "        dump_best_checkpoints=cfg.DUMP_BEST_CHECKPOINTS,\n",
        "        dump_last_checkpoints=cfg.DUMP_LAST_CHECKPOINTS,\n",
        "        best_checkpoints_warmup=cfg.BEST_CHECKPOINTS_WARMUP,\n",
        "    )\n",
        "\n",
        "    # train\n",
        "    best_model_wts = learner.train(\n",
        "        num_epochs=cfg.epoch_count,\n",
        "        lr=cfg.learning_rate,\n",
        "        step_size=cfg.optimizer_step,\n",
        "        gamma=cfg.optimizer_gamma,\n",
        "        weight_decay=cfg.weight_decay,\n",
        "        clip_grad=cfg.clip_grad,\n",
        "    )\n",
        "\n",
        "    # dump best model\n",
        "    torch.save(best_model_wts, exp_path / model_name)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # fix seeds for reproducibility\n",
        "    torch.manual_seed(0)\n",
        "    random.seed(0)\n",
        "    np.random.seed(0)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.use_deterministic_algorithms(True)\n",
        "\n",
        "    train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "eOj__fGYg0wp",
        "outputId": "f58aaebe-453d-4bc0-a635-9be0170015bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "train_model() missing 2 required positional arguments: 'config_path' and 'exp_path'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1085038055.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_deterministic_algorithms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: train_model() missing 2 required positional arguments: 'config_path' and 'exp_path'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "inf.py"
      ],
      "metadata": {
        "id": "mixrPKy4hAUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import click\n",
        "import lazycon\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# from core.metrics import get_metrics_df\n",
        "# from core.model import AUDIO_COLS, SoftMaxModel\n",
        "# from core.utils import collect_metrics_to_one, load_jsonl_as_df, raw_parse_dir\n",
        "\n",
        "DEVICE = \"cuda:0\"\n",
        "\n",
        "\n",
        "def run_single_inf(exp_path, test_manifest, with_metrics, recalculate, device):\n",
        "    # parse exp_path\n",
        "    # it may be exp path or path to model\n",
        "    if os.path.isdir(exp_path):\n",
        "        dir_path = exp_path\n",
        "        _path = Path(exp_path)\n",
        "        model_path = _path / _path.name\n",
        "    else:\n",
        "        dir_path = os.path.dirname(exp_path)\n",
        "        model_path = Path(exp_path)\n",
        "\n",
        "    dir_path = Path(dir_path)\n",
        "    model_name = model_path.name\n",
        "\n",
        "    # check the config\n",
        "    config_path = dir_path / \"train.config\"\n",
        "    assert os.path.exists(config_path), f\"No train.config in {dir_path}\"\n",
        "\n",
        "    # check the model\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"There is no saved model {model_path}. Nothing to inference\")\n",
        "        return None\n",
        "\n",
        "    # load the model\n",
        "    cfg = lazycon.load(config_path)\n",
        "    model = cfg.model\n",
        "    try:\n",
        "        model.to(device)\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        model.eval()\n",
        "    except Exception as exception:\n",
        "        print(f\"Problem with loading model {model_path}. Skipped\")\n",
        "        print(exception)\n",
        "        return None\n",
        "\n",
        "    # add last layer SoftMax to predict probabilities\n",
        "    model = SoftMaxModel(model)\n",
        "\n",
        "    # create predicts and metrics paths\n",
        "    predicts_path = Path(dir_path) / \"predicts\"\n",
        "    metrics_path = Path(dir_path) / \"metrics\"\n",
        "\n",
        "    predicts_path.mkdir(exist_ok=True)\n",
        "    metrics_path.mkdir(exist_ok=True)\n",
        "\n",
        "    # parse --vm folder/df\n",
        "    paths_to_inf = []\n",
        "\n",
        "    if os.path.isdir(test_manifest):\n",
        "        paths_to_inf = list(Path(test_manifest).glob(\"*.jsonl\"))\n",
        "    else:\n",
        "        paths_to_inf.append(test_manifest)\n",
        "\n",
        "    assert len(paths_to_inf) > 0, f\"No .jsonl here: {test_manifest}\"\n",
        "\n",
        "    # iterate over datasets for inference\n",
        "    for dataset_df_path in paths_to_inf:\n",
        "        dataset_df_path = Path(dataset_df_path)\n",
        "        dataset_df = load_jsonl_as_df(dataset_df_path)\n",
        "        # dataset_df = pd.read_csv(dataset_df_path, sep='\\t')\n",
        "        dataset_name = str(dataset_df_path.name).split(\".\", maxsplit=1)[0]\n",
        "        if with_metrics:\n",
        "            assert (\n",
        "                \"label\" in dataset_df.columns\n",
        "            ), f\"{dataset_name} hasn't 'label' column, but --with_metrics\"\n",
        "\n",
        "        # predict\n",
        "        predicts_tsv_path = (\n",
        "            predicts_path / f\"predicts_dataset_{dataset_name}_model_{model_name}.tsv\"\n",
        "        )\n",
        "\n",
        "        # if predicts exist and we don't want to recalculate it, but want to calculate metrics\n",
        "        if os.path.exists(predicts_tsv_path) and not recalculate:\n",
        "            if with_metrics:\n",
        "                metrics_csv_path = (\n",
        "                    metrics_path\n",
        "                    / f\"metrics_dataset_{dataset_name}_model_{model_name}.csv\"\n",
        "                )\n",
        "                if not os.path.exists(metrics_csv_path):\n",
        "                    print(\n",
        "                        f\"Predicts for {model_name} {dataset_name} exist. Calculating metrics\"\n",
        "                    )\n",
        "                    pred_df = pd.read_csv(predicts_tsv_path, sep=\"\\t\")\n",
        "\n",
        "                    pred_class = pred_df[AUDIO_COLS[0]].values\n",
        "                    gt_class = pred_df[\"label\"].values\n",
        "\n",
        "                    metrics_df = get_metrics_df(\n",
        "                        pred_class=pred_class, gt_class=gt_class, model_name=model_name\n",
        "                    )\n",
        "\n",
        "                    metrics_df.to_csv(metrics_csv_path)\n",
        "                else:\n",
        "                    print(\n",
        "                        f\"Predicts and metrics for {model_name} {dataset_name} exist. Skipped\"\n",
        "                    )\n",
        "            else:\n",
        "                print(\n",
        "                    f\"Predicts for {model_name} {dataset_name} are existed\"\n",
        "                    + \"--no_metrics, so metrics calculation is skipped\"\n",
        "                )\n",
        "            continue\n",
        "\n",
        "        # calculate predicts\n",
        "        running_outputs = []\n",
        "        ds = cfg.get_val_dataset(_df=dataset_df, ds_base_path=dataset_df_path.parent)\n",
        "        dataloader = cfg.get_val_dataloader(val_ds=ds)\n",
        "\n",
        "        print(f\"Calculating predicts and metrics: {model_name} {dataset_name}\")\n",
        "        for inputs, _ in tqdm(dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "            with torch.no_grad():\n",
        "                probs = model(inputs)\n",
        "\n",
        "            running_outputs.append(probs)\n",
        "\n",
        "        # MelEmotionsDataset changes order in df, so we should match predicts by id\n",
        "        _df = ds.df.copy()\n",
        "        pred_class = np.argmax(torch.cat(running_outputs).cpu().numpy(), axis=1)\n",
        "        probas = torch.cat(running_outputs).cpu().numpy()\n",
        "\n",
        "        _df[AUDIO_COLS[0]] = pred_class\n",
        "        for i in range(4):\n",
        "            _df[AUDIO_COLS[i + 1]] = probas[:, i]\n",
        "\n",
        "        # match preds by id\n",
        "        pred_df = dataset_df.copy()\n",
        "        _df = _df.set_index(\"id\").loc[pred_df.id]\n",
        "        for _col in AUDIO_COLS:\n",
        "            pred_df[_col] = _df[_col].values\n",
        "\n",
        "        pred_df.to_csv(predicts_tsv_path, index=False, sep=\"\\t\")\n",
        "\n",
        "        # calculate metrics\n",
        "        if with_metrics:\n",
        "            metrics_csv_path = (\n",
        "                metrics_path / f\"metrics_dataset_{dataset_name}_model_{model_name}.csv\"\n",
        "            )\n",
        "\n",
        "            pred_class = pred_df[AUDIO_COLS[0]].values\n",
        "            gt_class = pred_df[\"label\"].values\n",
        "\n",
        "            metrics_df = get_metrics_df(\n",
        "                pred_class=pred_class, gt_class=gt_class, model_name=model_name\n",
        "            )\n",
        "\n",
        "            metrics_df.to_csv(metrics_csv_path)\n",
        "\n",
        "\n",
        "@click.command()\n",
        "@click.option(\n",
        "    \"-exps_path\",\n",
        "    \"--exps_path\",\n",
        "    required=True,\n",
        "    type=click.Path(exists=True),\n",
        "    help=\"path folder with experiment folders (the experiment folder must have train.config file in)\",\n",
        ")\n",
        "@click.option(\n",
        "    \"-vm\",\n",
        "    \"--test_manifest\",\n",
        "    required=True,\n",
        "    type=click.Path(exists=True),\n",
        "    help=\"path to JSONL file/dir of JSONLs to inference\",\n",
        ")\n",
        "@click.option(\n",
        "    \"--with_metrics/--no_metrics\",\n",
        "    default=True,\n",
        "    help=\"calculate metrics for experiments\",\n",
        ")\n",
        "@click.option(\n",
        "    \"--recalculate/--no_recalculate\",\n",
        "    default=False,\n",
        "    help=\"recalculate existed predicts and metrics\",\n",
        ")\n",
        "@click.option(\n",
        "    \"--recalculate_dataset_metrics/--no_dataset_metrics\",\n",
        "    default=True,\n",
        "    help=\"recalculate existed grouped by dataset metrics\",\n",
        ")\n",
        "@click.option(\n",
        "    \"-device\", \"--device\", type=click.STRING, default=DEVICE, help=\"device to inference\"\n",
        ")\n",
        "def run_inf(\n",
        "    exps_path,\n",
        "    test_manifest,\n",
        "    with_metrics,\n",
        "    recalculate,\n",
        "    recalculate_dataset_metrics,\n",
        "    device,\n",
        "):\n",
        "    # parse folder, find experiments folders\n",
        "    exps_path = Path(exps_path)\n",
        "    experiment_paths = [p.parent for p in exps_path.glob(\"**/train.config\")]\n",
        "\n",
        "    # predict and calc metrics for a single experiment\n",
        "    for exp_path in experiment_paths:\n",
        "        run_single_inf(\n",
        "            exp_path=exp_path,\n",
        "            test_manifest=test_manifest,\n",
        "            with_metrics=with_metrics,\n",
        "            recalculate=recalculate,\n",
        "            device=device,\n",
        "        )\n",
        "\n",
        "    # aggregate metrics\n",
        "    metrics_dump_dir = exps_path / \"metrics\"\n",
        "    metrics_dump_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    if recalculate_dataset_metrics:\n",
        "        print(\"Aggregating metrics\")\n",
        "        dataset_models_paths, dataset_models = raw_parse_dir(\n",
        "            exps_path=exps_path, prefix=\"metrics\"\n",
        "        )\n",
        "        datasets = sorted(dataset_models.keys())\n",
        "        for dataset_name in datasets:\n",
        "            metric_dump_dir = metrics_dump_dir / f\"exps_{dataset_name}.csv\"\n",
        "            metric_df = collect_metrics_to_one(\n",
        "                [\n",
        "                    pd.read_csv(metrics_df_path)\n",
        "                    for metrics_df_path in dataset_models_paths[dataset_name].values()\n",
        "                ]\n",
        "            ).T\n",
        "            metric_df.to_csv(metric_dump_dir)\n",
        "    else:\n",
        "        print(\"--no_dataset_metrics, so metrics grouped by dataset are skipped\")\n",
        "\n",
        "    agg_metrics_paths = list(metrics_dump_dir.glob(\"*.csv\"))\n",
        "    if len(agg_metrics_paths) == 0:\n",
        "        print(\"There is no grouped by dataset metrics\")\n",
        "    else:\n",
        "        for agg_metrics_path in agg_metrics_paths:\n",
        "            # remove exps_ and .csv in aggregated metrics df name\n",
        "            dataset_name = str(agg_metrics_path.name)[5:-4]\n",
        "            metric_df = pd.read_csv(agg_metrics_path).set_index(\"Unnamed: 0\")\n",
        "            metric_df.index.name = \"\"\n",
        "            print(\"DATASET: \", dataset_name)\n",
        "            print(metric_df)\n",
        "            print(\"------------------------------------------------\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_inf()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "1F_-hLrig-dI",
        "outputId": "51aabc1f-f038-49e7-9bd8-7606ff9e5d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'lazycon'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1782378004.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclick\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlazycon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lazycon'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "base.config"
      ],
      "metadata": {
        "id": "48O0mPIthZvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from pathlib import Path\n",
        "base_path = Path('/workspace/data/paper_setups')\n",
        "\n",
        "# train data\n",
        "train_manifest_path = base_path / 'train' / 'crowd_train.jsonl'\n",
        "val_manifest_path = base_path / 'tests' / 'crowd_test.jsonl'\n",
        "\n",
        "# pretrain\n",
        "pt_model_path = None\n",
        "\n",
        "# exp hyperparams\n",
        "batch_size = 64\n",
        "epoch_count = 100\n",
        "learning_rate = 5e-4\n",
        "optimizer_step = 5\n",
        "optimizer_gamma = 1\n",
        "weight_decay = 1e-6\n",
        "clip_grad = False\n",
        "\n",
        "# augm and batch iter stuff\n",
        "collate_fn = adaptive_padding_collate_fn\n",
        "augm_func = get_augm_func(time_mask_param=40, freq_mask_param=16, crop_augm_max_cut_size=40)\n",
        "\n",
        "MAX_LENGTH = 16\n",
        "get_train_weights = None\n",
        "\n",
        "# model\n",
        "model_setting = [\n",
        "    # t, c, n, s\n",
        "    [1, 16, 1, 1],\n",
        "    [2, 32, 2, 2],\n",
        "    [2, 64, 6, 2],\n",
        "    [2, 128, 6, 2],\n",
        "]\n",
        "\n",
        "model = ConvSelfAttentionMobileNet(model_setting,\n",
        "                                   n_classes=4,\n",
        "                                   last_channel=128)\n",
        "\n",
        "\n",
        "def get_train_dataset(_df, ds_base_path):\n",
        "    return MelEmotionsDataset(_df,\n",
        "                              get_weights_func=get_train_weights,\n",
        "                              augm_transform=augm_func,\n",
        "                              base_path=ds_base_path)\n",
        "\n",
        "\n",
        "def get_val_dataset(_df, ds_base_path):\n",
        "    return MelEmotionsDataset(_df, base_path=ds_base_path)\n",
        "\n",
        "\n",
        "def get_train_dataloader(train_ds):\n",
        "    return DataLoader(train_ds, batch_size=batch_size, num_workers=1,\n",
        "                      collate_fn=collate_fn,\n",
        "                      sampler=LengthWeightedSampler(df=train_ds.df,\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    min_length=0.3,\n",
        "                                                    max_length=MAX_LENGTH,\n",
        "                                                    length_delta=0.3,\n",
        "                                                    decimals=1))\n",
        "\n",
        "\n",
        "def get_val_dataloader(val_ds):\n",
        "    return DataLoader(val_ds, batch_size=1, num_workers=4, shuffle=False)\n",
        "\n",
        "\n",
        "train_dataset = get_train_dataset(load_jsonl_as_df(train_manifest_path),\n",
        "                                  ds_base_path=train_manifest_path.parent)\n",
        "val_dataset = get_val_dataset(load_jsonl_as_df(val_manifest_path),\n",
        "                              ds_base_path=val_manifest_path.parent)\n",
        "\n",
        "dataloaders = {'train': get_train_dataloader(train_ds=train_dataset),\n",
        "               'validate': get_val_dataloader(val_ds=val_dataset)}\n",
        "\n",
        "DUMP_BEST_CHECKPOINTS = True\n",
        "DUMP_LAST_CHECKPOINTS = True\n",
        "BEST_CHECKPOINTS_WARMUP = 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "EtE8OquRhZTc",
        "outputId": "3bf01781-f166-469b-960d-ff2d7ab15aa7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/workspace/data/paper_setups/train/crowd_train.jsonl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-827942412.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m train_dataset = get_train_dataset(load_jsonl_as_df(train_manifest_path),\n\u001b[0m\u001b[1;32m     69\u001b[0m                                   ds_base_path=train_manifest_path.parent)\n\u001b[1;32m     70\u001b[0m val_dataset = get_val_dataset(load_jsonl_as_df(val_manifest_path),\n",
            "\u001b[0;32m/tmp/ipython-input-1668891216.py\u001b[0m in \u001b[0;36mload_jsonl_as_df\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_jsonl_as_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/workspace/data/paper_setups/train/crowd_train.jsonl'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "crown_largd.config"
      ],
      "metadata": {
        "id": "7d3hoUYZhQSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data\n",
        "train_manifest_path = base_path / 'crowd_large.jsonl'\n",
        "val_manifest_path = base_path / 'test' / 'crowd_test.jsonl'\n",
        "\n",
        "# pretrain\n",
        "pt_model_path = None\n",
        "\n",
        "# exp hyperparams\n",
        "batch_size = 64\n",
        "epoch_count = 100\n",
        "learning_rate = 1e-3\n",
        "optimizer_step = 5\n",
        "optimizer_gamma = 1\n",
        "weight_decay = 1e-6\n",
        "clip_grad = False"
      ],
      "metadata": {
        "id": "p3M3kIvwhUrm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
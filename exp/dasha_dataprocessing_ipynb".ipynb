{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1MkOnIXkRXDFjVaNypxwWtjw4sUHcrNrF",
      "authorship_tag": "ABX9TyMTx+3UeS3P3v86bV7CSMPq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tihunn/emotion_testing/blob/main/exp/dasha_dataprocessing_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "datacls.py"
      ],
      "metadata": {
        "id": "9luM7G2E4i3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Any\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "#                               AGGREGATION\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DawidSkeneEntryDataclass:\n",
        "    task: str\n",
        "    worker: str\n",
        "    label: Any\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DawidSkeneResultDataclass:\n",
        "    task: str\n",
        "    pred: str\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class MarkupDataclass:\n",
        "    hash_id: str\n",
        "    audio_path: str\n",
        "    duration: str\n",
        "    annotator_emo: str\n",
        "    golden_emo: str\n",
        "    speaker_text: str\n",
        "    speaker_emo: str\n",
        "    source_id: str\n",
        "    audio_path: str\n",
        "    annotator_emo: str\n",
        "    annotator_id: str\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class AggDataclass:\n",
        "    hash_id: str\n",
        "    audio_path: str\n",
        "    duration: str\n",
        "    emotion: str\n",
        "    golden_emo: str\n",
        "    speaker_text: str\n",
        "    speaker_emo: str\n",
        "    source_id: str\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "#                               FEATURES\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataWithFeaturesEntryclass:\n",
        "    wav_path: str\n",
        "    wav_id: str\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "#                               EXP\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataForExp:\n",
        "    id: str\n",
        "    tensor: str\n",
        "    wav_length: str\n",
        "    label: int\n",
        "    emotion: str"
      ],
      "metadata": {
        "id": "LzW5j5OG4gkY"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dawidskene.py"
      ],
      "metadata": {
        "id": "9tLkIFza4xHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install crowd-kit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCcXK7yG5DMY",
        "outputId": "d10254e3-b5fc-4738-a7ab-13b7296e53e0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting crowd-kit\n",
            "  Downloading crowd_kit-1.4.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from crowd-kit) (25.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from crowd-kit) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from crowd-kit) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from crowd-kit) (2.2.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from crowd-kit) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from crowd-kit) (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from crowd-kit) (4.67.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from crowd-kit) (4.55.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.0->crowd-kit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.0->crowd-kit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.0->crowd-kit) (2025.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->crowd-kit) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->crowd-kit) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->crowd-kit) (2024.11.6)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->crowd-kit) (1.16.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->crowd-kit) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers->crowd-kit) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers->crowd-kit) (0.34.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers->crowd-kit) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers->crowd-kit) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers->crowd-kit) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers->crowd-kit) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->crowd-kit) (0.6.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->crowd-kit) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->crowd-kit) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->crowd-kit) (1.1.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.0->crowd-kit) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->crowd-kit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->crowd-kit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->crowd-kit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->crowd-kit) (2025.8.3)\n",
            "Downloading crowd_kit-1.4.1-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: crowd-kit\n",
            "Successfully installed crowd-kit-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "import pandas as pd\n",
        "from crowdkit.aggregation import DawidSkene as CrowdKitDawidSkene\n",
        "\n",
        "\n",
        "def get_dawidskene_pred(\n",
        "    data: List[DawidSkeneEntryDataclass],\n",
        "    threshold: float,\n",
        "    meta_path: Path,\n",
        "    n_iter: int = 100,\n",
        ") -> List[DawidSkeneResultDataclass]:\n",
        "    labels = {row.label for row in data}\n",
        "    assert \"task\" not in labels, 'Labels cant contains the name \"task\"!'\n",
        "    aggregated_labels = CrowdKitDawidSkene(n_iter=n_iter).fit_predict_proba(\n",
        "        pd.DataFrame(data)\n",
        "    )\n",
        "    aggregated_labels.to_csv(meta_path, sep=\"\\t\")\n",
        "\n",
        "    aggregated_labels_list = aggregated_labels.reset_index().to_dict(\"records\")\n",
        "    aggregated_data = []\n",
        "    for row in aggregated_labels_list:\n",
        "        tmp_dict = {val: key for key, val in row.items() if key in labels}\n",
        "        max_item_proba = max(tmp_dict)\n",
        "        if max_item_proba >= threshold:\n",
        "            key_with_max_value = tmp_dict[max_item_proba]\n",
        "            aggregated_row = DawidSkeneResultDataclass(\n",
        "                task=row[\"task\"],\n",
        "                pred=key_with_max_value,\n",
        "            )\n",
        "            aggregated_data.append(aggregated_row)\n",
        "    return aggregated_data"
      ],
      "metadata": {
        "id": "z6OeYMvs40Gp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "aggregation.py"
      ],
      "metadata": {
        "id": "KLTSApto4H1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from enum import Enum\n",
        "from pathlib import Path\n",
        "from typing import Dict, List\n",
        "\n",
        "\n",
        "HEADER = \"\\t\".join(\n",
        "    [\n",
        "        \"hash_id\",\n",
        "        \"wav_path\",\n",
        "        \"duration\",\n",
        "        \"emotion\",\n",
        "        \"golden_emo\",\n",
        "        \"speaker_text\",\n",
        "        \"speaker_emo\",\n",
        "        \"source_id\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "HEADER_EXP = \"\\t\".join([\"id\", \"tensor\", \"wav_lengh\", \"label\"])\n",
        "\n",
        "\n",
        "class Emotion(Enum):\n",
        "    ANGRY = 0\n",
        "    SAD = 1\n",
        "    NEUTRAL = 2\n",
        "    POSITIVE = 3\n",
        "\n",
        "\n",
        "def read_data_markup(dataset_path: Path, use_tsv: bool) -> List[MarkupDataclass]:\n",
        "    markup_data = []\n",
        "    if use_tsv:\n",
        "        with open(\n",
        "            dataset_path.parent / (dataset_path.stem + \".tsv\"), \"r\", encoding=\"utf-8\"\n",
        "        ) as file:\n",
        "            headers = file.readline().rstrip(\"\\r\\n\").split(\"\\t\")\n",
        "            for line in file:\n",
        "                line_data = line.strip(\"\\r\\n\").split(\"\\t\")\n",
        "                string = dict(zip(headers, line_data))\n",
        "                row = MarkupDataclass(**string)\n",
        "                markup_data.append(row)\n",
        "    else:\n",
        "        with open(\n",
        "            dataset_path.parent / (dataset_path.stem + \".jsonl\"), \"r\", encoding=\"utf-8\"\n",
        "        ) as file:\n",
        "            for line in file:\n",
        "                row = MarkupDataclass(**json.loads(line))\n",
        "                markup_data.append(row)\n",
        "    return markup_data\n",
        "\n",
        "\n",
        "def agg_data_to_file(\n",
        "    file_path: Path, agg_data: List[AggDataclass], use_tsv: bool\n",
        ") -> None:\n",
        "    if use_tsv:\n",
        "        with open(\n",
        "            file_path.parent / (file_path.stem + \".tsv\"), \"w\", encoding=\"utf-8\"\n",
        "        ) as file:\n",
        "            print(HEADER, file=file, end=os.linesep)\n",
        "            for row in agg_data:\n",
        "                print(\"\\t\".join(row.__dict__.values()), file=file, end=os.linesep)\n",
        "    else:\n",
        "        with open(\n",
        "            file_path.parent / (file_path.stem + \".jsonl\"), \"w\", encoding=\"utf-8\"\n",
        "        ) as file:\n",
        "            for row in agg_data:\n",
        "                line = json.dumps(row.__dict__, ensure_ascii=False)\n",
        "                print(line, file=file, end=os.linesep)\n",
        "\n",
        "\n",
        "def exp_data_to_file(\n",
        "    file_path: Path, exp_data: List[DataForExp], use_tsv: bool\n",
        ") -> None:\n",
        "    if use_tsv:\n",
        "        with open(\n",
        "            file_path.parent / (file_path.stem + \".tsv\"), \"w\", encoding=\"utf-8\"\n",
        "        ) as file:\n",
        "            print(HEADER_EXP, file=file, end=os.linesep)\n",
        "            for row in exp_data:\n",
        "                line = \"\\t\".join(list(map(str, row.__dict__.values())))\n",
        "                print(line, file=file, end=os.linesep)\n",
        "    else:\n",
        "        with open(\n",
        "            file_path.parent / (file_path.stem + \".jsonl\"), \"w\", encoding=\"utf-8\"\n",
        "        ) as file:\n",
        "            for row in exp_data:\n",
        "                line = json.dumps(row.__dict__, ensure_ascii=False)\n",
        "                print(line, file=file, end=os.linesep)\n",
        "\n",
        "\n",
        "def filter_data(\n",
        "    markup_data: List[MarkupDataclass],\n",
        "    aggregated_data_dict: Dict[str, str],\n",
        "    dataset: str,\n",
        ") -> List[AggDataclass]:\n",
        "    agg_data = []\n",
        "    used_wavs = set()\n",
        "    for row in markup_data:\n",
        "        if row.hash_id in used_wavs:\n",
        "            continue\n",
        "        if row.hash_id in aggregated_data_dict:\n",
        "            good_agg_row = AggDataclass(\n",
        "                hash_id=row.hash_id,\n",
        "                audio_path=str(Path(\"..\", \"..\", dataset, row.audio_path)),\n",
        "                duration=row.duration,\n",
        "                emotion=aggregated_data_dict[row.hash_id],\n",
        "                golden_emo=row.golden_emo,\n",
        "                speaker_text=row.speaker_text,\n",
        "                speaker_emo=row.speaker_emo,\n",
        "                source_id=row.source_id,\n",
        "            )\n",
        "            agg_data.append(good_agg_row)\n",
        "        used_wavs.add(row.hash_id)\n",
        "    return agg_data\n",
        "\n",
        "\n",
        "def make_exp_data(agg_data: List[AggDataclass]) -> List[DataForExp]:\n",
        "    exp_data = []\n",
        "    for row in agg_data:\n",
        "        if (\n",
        "            not isinstance(row.golden_emo, str) or row.golden_emo == \"\"\n",
        "        ) and row.emotion != \"other\":\n",
        "            exp_row = DataForExp(\n",
        "                id=row.hash_id,\n",
        "                tensor=str(Path(\"..\", \"..\", \"features\", row.hash_id + \".npy\")),\n",
        "                wav_length=row.duration,\n",
        "                label=Emotion[row.emotion.upper()].value,\n",
        "                emotion=row.emotion,\n",
        "            )\n",
        "            exp_data.append(exp_row)\n",
        "    return exp_data\n",
        "\n",
        "\n",
        "def aggregate_data(\n",
        "    data_path: Path, out_path: Path, use_tsv: bool, dawidskene_threshold: float\n",
        ") -> None:\n",
        "\n",
        "    markup_data = [\"podcast_test\", \"podcast_train\", \"crowd_train\", \"crowd_test\"]\n",
        "    data = {}\n",
        "    all_data = []\n",
        "    for dataset in markup_data:\n",
        "        data[dataset] = read_data_markup(\n",
        "            dataset_path=Path(data_path, dataset, \"raw_\" + dataset),\n",
        "            use_tsv=use_tsv,\n",
        "        )\n",
        "        all_data += data[dataset]\n",
        "\n",
        "    data_for_agg = []\n",
        "    for row in all_data:\n",
        "        row_for_agg = DawidSkeneEntryDataclass(\n",
        "            task=row.hash_id,\n",
        "            worker=row.annotator_id,\n",
        "            label=row.annotator_emo,\n",
        "        )\n",
        "        data_for_agg.append(row_for_agg)\n",
        "\n",
        "    aggregated_data = get_dawidskene_pred(\n",
        "        data=data_for_agg,\n",
        "        threshold=dawidskene_threshold,\n",
        "        meta_path=data_path / \"meta.tsv\",\n",
        "    )\n",
        "\n",
        "    aggregated_data_dict = {row.task: row.pred for row in aggregated_data}\n",
        "\n",
        "    exp_data = {}\n",
        "    for dataset in markup_data:\n",
        "        agg_data = filter_data(\n",
        "            markup_data=data[dataset],\n",
        "            aggregated_data_dict=aggregated_data_dict,\n",
        "            dataset=dataset,\n",
        "        )\n",
        "        exp_data[dataset] = make_exp_data(agg_data=agg_data)\n",
        "        exp_data_to_file(\n",
        "            file_path=out_path / dataset.rsplit(\"_\", maxsplit=1)[-1] / dataset,\n",
        "            exp_data=exp_data[dataset],\n",
        "            use_tsv=use_tsv,\n",
        "        )\n",
        "        agg_data_to_file(\n",
        "            file_path=out_path / \"aggregated_dataset\" / dataset,\n",
        "            agg_data=agg_data,\n",
        "            use_tsv=use_tsv,\n",
        "        )\n",
        "    exp_data_to_file(\n",
        "        file_path=out_path / \"train\" / \"train\",\n",
        "        exp_data=exp_data[\"podcast_train\"] + exp_data[\"crowd_train\"],\n",
        "        use_tsv=use_tsv,\n",
        "    )\n",
        "    exp_data_to_file(\n",
        "        file_path=Path(out_path / \"test\" / \"test\"),\n",
        "        exp_data=exp_data[\"podcast_test\"] + exp_data[\"crowd_test\"],\n",
        "        use_tsv=use_tsv,\n",
        "    )"
      ],
      "metadata": {
        "id": "pO5PvzOP4He8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "calc_features.py"
      ],
      "metadata": {
        "id": "iuUNw6R1525d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from typing import List, Set\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def create_features(\n",
        "    data: List[DataWithFeaturesEntryclass],\n",
        "    wavs_names: Set[str],\n",
        "    features_dump_path: Path,\n",
        "    dataset_name: str,\n",
        "    recalculate_feature: bool,\n",
        "    hop_length_coef: float = 0.01,\n",
        "    win_length_coef: float = 0.02,\n",
        "    sample_rate: int = 16000,\n",
        "    n_mels: int = 64,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    As an input all models use standard speech features:\n",
        "    64 Mel-filterbank calculated from 20ms windows with a 10ms overlap.\n",
        "    \"\"\"\n",
        "    if recalculate_feature:\n",
        "        if len(data) != len(wavs_names):\n",
        "            print(\n",
        "                f\"{len(wavs_names) - len(data)} wav files are missing for {dataset_name}\"\n",
        "            )\n",
        "        hop_length = int(sample_rate * hop_length_coef)\n",
        "        win_length = int(sample_rate * win_length_coef)\n",
        "        for row in tqdm(data):\n",
        "            data, rate = librosa.load(row.wav_path, sr=sample_rate)\n",
        "            if len(data) != 0:\n",
        "                spec = librosa.feature.melspectrogram(\n",
        "                    y=data,\n",
        "                    sr=rate,\n",
        "                    hop_length=hop_length,\n",
        "                    n_fft=win_length,\n",
        "                    n_mels=n_mels,\n",
        "                )\n",
        "            else:\n",
        "                raise AttributeError\n",
        "            mel_spec = librosa.power_to_db(spec, ref=np.max)\n",
        "            np.save(features_dump_path / f\"{row.wav_id}.npy\", mel_spec[None])\n",
        "        print(\n",
        "            f\"({len(data)}/{len(wavs_names)}) features have been calculated for {dataset_name}\"\n",
        "        )\n",
        "    else:\n",
        "        ready_features = {elm.stem for elm in features_dump_path.glob(\"*.npy\")}\n",
        "        wav_to_features = {wav for wav in wavs_names if not wav in ready_features}\n",
        "        data_to_culc = [wav for wav in data if wav.wav_id in wav_to_features]\n",
        "\n",
        "        if len(data_to_culc) != len(wav_to_features):\n",
        "            print(\n",
        "                f\"{len(wav_to_features) - len(data_to_culc)} wav files are missing for {dataset_name}\"\n",
        "            )\n",
        "\n",
        "        if not data_to_culc:\n",
        "            print(\n",
        "                f\"All({len({wav for wav in wavs_names if wav in ready_features})}/{len(wavs_names)}) features have been calculated for {dataset_name}\"\n",
        "            )\n",
        "            return\n",
        "\n",
        "        hop_length = int(sample_rate * hop_length_coef)\n",
        "        win_length = int(sample_rate * win_length_coef)\n",
        "        for row in tqdm(data_to_culc):\n",
        "            data, rate = librosa.load(row.wav_path, sr=sample_rate)\n",
        "            if len(data) != 0:\n",
        "                spec = librosa.feature.melspectrogram(\n",
        "                    y=data,\n",
        "                    sr=rate,\n",
        "                    hop_length=hop_length,\n",
        "                    n_fft=win_length,\n",
        "                    n_mels=n_mels,\n",
        "                )\n",
        "            else:\n",
        "                raise AttributeError\n",
        "            mel_spec = librosa.power_to_db(spec, ref=np.max)\n",
        "            np.save(features_dump_path / f\"{row.wav_id}.npy\", mel_spec[None])\n",
        "\n",
        "\n",
        "def load_features(\n",
        "    wavs_path: Path,\n",
        "    wavs_names: Set[str],\n",
        "    result_dir: Path,\n",
        "    dataset_name: str,\n",
        "    recalculate_feature: bool,\n",
        ") -> None:\n",
        "    wavs = []\n",
        "    for elm in wavs_path.glob(\"*.wav\"):\n",
        "        wavs.append(DataWithFeaturesEntryclass(wav_path=str(elm), wav_id=elm.stem))\n",
        "    create_features(\n",
        "        data=wavs,\n",
        "        wavs_names=wavs_names,\n",
        "        features_dump_path=result_dir / \"features\",\n",
        "        dataset_name=dataset_name,\n",
        "        recalculate_feature=recalculate_feature,\n",
        "    )"
      ],
      "metadata": {
        "id": "bgD54nui52eH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "processing.py by gpt"
      ],
      "metadata": {
        "id": "O7U2ZyfI7IZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "def processing(\n",
        "    dataset_path: str,\n",
        "    use_tsv: bool = False,\n",
        "    recalculate_features: bool = False,\n",
        "    threshold: float = 0.9,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Processing raw data for training\n",
        "    \"\"\"\n",
        "    if threshold > 1 or threshold < 0:\n",
        "        raise AttributeError(\"Threshold must be between 0 and 1\")\n",
        "\n",
        "    np.seterr(divide=\"ignore\")\n",
        "\n",
        "    public_data = Path(dataset_path)\n",
        "    result_dir = public_data / f\"processed_dataset_0{int(threshold*100)}\"\n",
        "\n",
        "    # создаём подпапки\n",
        "    path_names = [\"train\", \"aggregated_dataset\", \"test\"]\n",
        "    for path_name in path_names:\n",
        "        (result_dir / path_name).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    (public_data / \"features\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # обрабатываем все наборы\n",
        "    data_types = [\"crowd_train\", \"crowd_test\", \"podcast_train\", \"podcast_test\"]\n",
        "    for data_type in data_types:\n",
        "        wavs_path = public_data / data_type / \"wavs\"\n",
        "        data = read_data_markup(\n",
        "            dataset_path=public_data / data_type / (\"raw_\" + data_type),\n",
        "            use_tsv=use_tsv,\n",
        "        )\n",
        "        wavs_names = {Path(row.audio_path).stem for row in data}\n",
        "        load_features(\n",
        "            wavs_path=wavs_path,\n",
        "            wavs_names=wavs_names,\n",
        "            result_dir=public_data,\n",
        "            dataset_name=data_type,\n",
        "            recalculate_feature=recalculate_features,\n",
        "        )\n",
        "\n",
        "    # агрегируем\n",
        "    aggregate_data(public_data, result_dir, use_tsv, threshold)\n"
      ],
      "metadata": {
        "id": "cvN9MTRY7bpj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "run process"
      ],
      "metadata": {
        "id": "KtFavct-7h5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processing(\n",
        "    dataset_path=\"/content/drive/MyDrive/crowd\",  # путь к твоему датасету\n",
        "    use_tsv=False,\n",
        "    recalculate_features=False,\n",
        "    threshold=0.9,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTdpkUWE7lJV",
        "outputId": "518929e8-3f9b-4d5d-df2c-f62f7bab6f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "184626 wav files are missing for crowd_train\n",
            "All(0/184626) features have been calculated for crowd_train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 173/17042 [04:09<228:45:42, 48.82s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "из-за гугл колаба и гугл диска файлы длительность до 10 секунд обрабатываются крайне долго..."
      ],
      "metadata": {
        "id": "Fe6WmA8_FQPb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# processing.py by dasha. Comparison cell"
      ],
      "metadata": {
        "id": "TC66zwJW325S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import click\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "@click.command()\n",
        "@click.option(\n",
        "    \"-dataset_path\",\n",
        "    \"--dataset_path\",\n",
        "    required=True,\n",
        "    type=click.Path(exists=True),\n",
        "    help=\"dataset_path\",\n",
        ")\n",
        "@click.option(\n",
        "    \"--use_tsv\", \"-tsv\", is_flag=True, default=False, help=\"use tsv to read/write\"\n",
        ")\n",
        "@click.option(\n",
        "    \"--recalculate_features\",\n",
        "    \"-rf\",\n",
        "    is_flag=True,\n",
        "    default=False,\n",
        "    help=\"recalculate features\",\n",
        ")\n",
        "@click.option(\n",
        "    \"--threshold\",\n",
        "    \"-threshold\",\n",
        "    default=0.9,\n",
        "    help=\"Dawidskene threshold\",\n",
        "    show_default=True,\n",
        ")\n",
        "def processing(\n",
        "    dataset_path: str, use_tsv: bool, recalculate_features: bool, threshold: float\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    processing raw data for training\n",
        "    \"\"\"\n",
        "    if threshold > 1 or threshold < 0:\n",
        "        raise AttributeError\n",
        "\n",
        "    np.seterr(divide=\"ignore\")\n",
        "\n",
        "    public_data = Path(dataset_path)\n",
        "    result_dir = public_data / f\"processed_dataset_0{int(threshold*100)}\"\n",
        "\n",
        "    path_names = [\"train\", \"aggregated_dataset\", \"test\"]\n",
        "    for path_name in path_names:\n",
        "        (result_dir / path_name).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    (public_data / \"features\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    data_types = [\"crowd_train\", \"crowd_test\", \"podcast_train\", \"podcast_test\"]\n",
        "    for data_type in data_types:\n",
        "        wavs_path = public_data / data_type / \"wavs\"\n",
        "        data = read_data_markup(\n",
        "            dataset_path=public_data / data_type / (\"raw_\" + data_type),\n",
        "            use_tsv=use_tsv,\n",
        "        )\n",
        "        wavs_names = {Path(row.audio_path).stem for row in data}\n",
        "        load_features(\n",
        "            wavs_path=wavs_path,\n",
        "            wavs_names=wavs_names,\n",
        "            result_dir=public_data,\n",
        "            dataset_name=data_type,\n",
        "            recalculate_feature=recalculate_features,\n",
        "        )\n",
        "\n",
        "    aggregate_data(public_data, result_dir, use_tsv, threshold)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    processing()  # pylint: disable=no-value-for-parameter"
      ],
      "metadata": {
        "id": "gta42N6s31un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-lrhv3Z_32VD"
      }
    }
  ]
}